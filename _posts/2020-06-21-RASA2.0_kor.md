---
layout: post
title:  " RASA 2.0 한글 적용"
date:   2020-06-21 19:31:29 +0900
category: RASA
--- 
# RASA 2.0 한글 적용

# mecab-ko-dic

*   mecab-ko-dic은 오픈 소스 형태소 분석엔진인 MeCab을 사용하여, 한국어 형태소 분석을 하기 위한 프로젝트입니다. 말뭉치 학습과 사전 목록은 모두 21세기 세종계획의 성과물을 사용 한다
*   말뭉치 학습과 사전 목록 일부는 21세기 세종계획의 성과물을 사용 하였다.
*   mecab-ko-dic은 21세기 세종계획 모든 현대 말뭉치에서 50문장씩을 추출하여 학습에 이용하였다. (총 23,615 문장)

# MeCab

*   MeCab은 교토 대학 정보학 연구과 - 일본 NTT 커뮤니케이션 과학 기초 연구소 공동 연구 유닛 프로젝트 를 통해 개발 된 오픈 소스 형태소 분석 엔진입니다. 언어, 사전, 코퍼스에 의존하지 않는 범용적인 설계를 기본 방침으로하고 있다.
*   언어, 사전, 코퍼스에 의존하지 않는 범용적인 설계를 기본 방침으로하고 있다.
*   매개 변수 추정에 Conditional Random Fields ( CRF )를 사용하고 있으며, ChaSen 가 채용하고있는 은닉 마르코프 모델에 비해 성능이 향상하고 있다.

# KoNLPy

*   KoNLPy는 한국어 정보처리를 위한 파이썬 패키지 이다.
*   자연어처리(NLP)에서 형태소를 분리(형태소 단위 토크나이징)하는 데이터 전처리가 필요한데 이때 한국어 데이터 전처리를 할 때 많이 사용하는 패키지이다.
*   텍스트를 형태소 단위로 분리하는 방법 중에는

```ruby
1. 단어->품사 형태로 딕셔너리를 정의하고 이를 이용해 단어를 품사로 분리하는 방법. 
   (딕셔너리가 동일해도 방법에 따라 형태소가 분리되는 결과가 다르다.)

2. 딕셔너리를 사용하지 않고 모델을 통해 학습시키는 방법. 
   (어떤 품사인지까지 알 수 없고 문장에서 단어를 구별해내는 방법.)
```

이 있고 KoNLPy는 1번의 방법을 사용한다.

*   KoNLPy에는 총 5가지의 형태소 분석 방법을 제공하고 이는 Hannanum, Kkma, Komoran, Mecab, Okt(구 Twitter) 5가지 클래스로 제공된다.
*   KoNLPy는 자바VM환경에서 작동 하므로 JDK와 JPype를 설치 한 후 install 해야 한다. 이런 번거로움을 피하기 위해 Anaconda 환경에서 설치 한다.

# Anaconda에 KoNLPy와 MeCab 설치 하기

```ruby
-- AWS OPEN JDK 11 설치
$ wget -O- https://apt.corretto.aws/corretto.key | sudo apt-key add - 
 sudo add-apt-repository 'deb https://apt.corretto.aws stable main'
$ sudo apt-get update; sudo apt-get install -y java-11-amazon-corretto-jdk

-- KoNLPy 설치 및 확인
$ pip install konlpy
$ pip list | grep konlpy
konlpy                             0.5.2

-- MeCab 설치
$ wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
$ tar -zxvf mecab-0.996-ko-0.9.2.tar.gz
$ cd mecab-0.996-ko-0.9.2/
$ ./configure
$ make
$ make check
$ sudo make install

-- MeCab 버전 확인 (오류 발생)
$ mecab --version
mecab: error while loading shared libraries: libmecab.so.2: cannot open shared object file: No such file or directory

-- 라이브러리 로딩 후 재 확인
$ sudo ldconfig
$ mecab --version
mecab of 0.996/ko-0.9.2

-- Mecab-ko-dic 설치
$ wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
$ tar -zxvf mecab-ko-dic-2.1.1-20180720.tar.gz
$ cd mecab-ko-dic-2.1.1-20180720/
$ sudo apt-get install automake
$ ./autogen.sh
$ ./configure
$ make
$ sudo make install

-- mecab python 설치
$ git clone https://bitbucket.org/eunjeon/mecab-python-0.996.git
$ cd mecab-python-0.996/
$ python3 setup.py build
$ python3 setup.py install

(Mac) $ pip install mecab-python3
-- Mecab 설치 확인
$ python
>>> from konlpy.tag import Mecab
>>> m = Mecab()
>>> m.pos('이상하게 생각해도 어쩔 수 없어 반했으니까')
[('이상', 'NNG'), ('하', 'XSV'), ('게', 'EC'), ('생각', 'NNG'), ('해도', 'XSV+EC'), ('어쩔', 'VV+ETM'), ('수', 'NNB'), ('없', 'VA'), ('어', 'EC'), ('반했', 'VV+EP'), ('으니까', 'EC')]
>>> m.pos('사탕처럼 달콤하다는데')
[('사탕', 'NNG'), ('처럼', 'JKB'), ('달콤', 'XR'), ('하', 'XSA'), ('다는데', 'EC')]
```

# spacy 설치

```ruby
$ conda install -c conda-forge spacy
$ python -m spacy download en_core_web_md 
$ python -m spacy link en_core_web_md en
$ python -m spacy download xx_ent_wiki_sm
```

## RASA 2.0.x 에 한글 환경 셋팅

### 첨부된 crf\_entity\_extractor\_korean.py 파일과 korean\_tokenizer.py 을 다음 디렉토리에 복사한다

```ruby
$ cp crf_entity_extractor_korean.py /Users/maruhan/opt/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/tokenizers
$ cp korean_tokenizer.py /Users/maruhan/opt/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/extractor
```

### rasa/nlu/registry.py 파일에 다음을 추가한다

```ruby
$ cd /Users/maruhan/opt/anaconda3/envs/py379/lib/python3.7/site-packages/
$ cd rasa/nlu
$ vi registry.py

from rasa.nlu.extractors.crf_entity_extractor_korean import CRFEntityExtractorKorean
from rasa.nlu.tokenizers.korean_tokenizer import KoreanTokenizer
.
.
.

component_classes = [
    # utils
    SpacyNLP,
    MitieNLP,
    HFTransformersNLP,
    # tokenizers
    KoreanTokenizer,
    MitieTokenizer,
    SpacyTokenizer,
    WhitespaceTokenizer,
    ConveRTTokenizer,
    JiebaTokenizer,
    LanguageModelTokenizer,
    # extractors
    SpacyEntityExtractor,
    MitieEntityExtractor,
    CRFEntityExtractor,
    CRFEntityExtractorKorean,
    DucklingEntityExtractor,
    .
    .
    .
```

## rasa train 실행시 오류 수정

### CASE 1 : 오류메시지 확인 후 수정

```ruby
File "/Users/maruhan/opt/anaconda3/envs/py369/lib/python3.6/site-packages/rasa/nlu/extractors/crf_entity_extractor_korean.py", line 7, in <module>

1. 업로드한 crf_entity_extractor_korean.py 파일 수정
from rasa.nlu.extractors import EntityExtractor ==> from rasa.nlu.extractors.extractor import EntityExtractor
from rasa.nlu.tokenizers import Token ==> from rasa.nlu.tokenizers.tokenizer import Token
from rasa.nlu.training_data import Message, TrainingData
 ==> 
from rasa.shared.nlu.training_data.message import Message
from rasa.shared.nlu.training_data.training_data import TrainingDat

2. 업로드한  korean_tokenizer.py.py 파일 수정
from rasa.nlu.tokenizers import Token, Tokenize ==> from rasa.nlu.tokenizers.tokenizer import Token, Tokenize
from rasa.nlu.training_data import Message, TrainingData
 ==> 
from rasa.shared.nlu.training_data.message import Message
from rasa.shared.nlu.training_data.training_data import TrainingDat

$ vi 
```

### CASE 2 : 첨부된 파일 rasa/nlu 폴더에 업데이트

```ruby
-- rasa 버전 확인
$ pip list |grep rasa
rasa                    2.0.2
rasa-sdk                2.0.0
rasa-x                  0.33.2

1. 첨부된 http://pms.fintechnology.co.kr:8080/attachments/64/registry.py 파일을
-- /home/goalpae/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/nlu 에 복사
-- rasa 디렉토리 위치 확인
$ pwd
/home/goalpae/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/nlu
$ cp ~/download/resigtry.py  ./

2. 첨부된 http://pms.fintechnology.co.kr:8080/attachments/66/korean_tokenizer.py 파일을
-- /home/goalpae/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/nlu/tokenizers 에 복사
-- rasa 디렉토리 위치 확인
$ pwd
/home/goalpae/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/nlu/tokenizers
$ cp ~/download/korean_tokenizer.py  ./

3. 첨부된 http://pms.fintechnology.co.kr:8080/attachments/65/crf_entity_extractor_korean.py 파일을
-- /home/goalpae/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/nlu/extractors 에 복사
-- rasa 디렉토리 위치 확인
/home/goalpae/anaconda3/envs/py379/lib/python3.7/site-packages/rasa/nlu/extractors
$ cp ~/download/crf_entity_extractor_korean.py  ./
```

### rasa project directory 에서 config.yml 파일 변경 (pipeline 추가변경)

```ruby
# Configuration for Rasa NLU.
# https://rasa.com/docs/rasa/nlu/components/
language: ko

pipeline:
  - name: KoreanTokenizer
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CRFEntityExtractorKorean
  - name: EntitySynonymMapper
  - name: CountVectorsFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: "char_wb"
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 100
  - name: EntitySynonymMapper
  - name: ResponseSelector
    epochs: 100

# Configuration for Rasa Core.
# https://rasa.com/docs/rasa/core/policies/
policies:
  - name: TEDPolicy
    epochs: 300
    max_history: 3
  - name: MemoizationPolicy
    max_history: 3
  - name: RulePolicy
    core_fallback_threshold: 0.3
    core_fallback_action_name: "utter_fallback"
    enable_fallback_prediction: Tru
  
```


# 첨부 파일

<figure class="file"><a href= "/attachments/crf_entity_extractor_korean2.0.py" alt="crf_entity_extractor_korean">crf_entity_extractor_korean2.0.py</a></figure>

<figure class="file"><a href= "/attachments/registry2.0.py" alt="crf_entity_extractor_korean">registry2.0.py</a></figure>

<figure class="file"><a href= "/attachments/korean_tokenizer2.0.py" alt="crf_entity_extractor_korean">korean_tokenizer2.0.py</a></figure>



end