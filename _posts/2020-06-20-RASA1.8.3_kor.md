---
layout: post
title:  "RASA 1.8.3 한글 적용"
date:   2020-06-20 19:31:29 +0900
category: RASA
--- 
# RASA 1.8.3 한글 적용

## KoNLPy 설치 및 확인

```ruby
$ pip install konlpy
$ pip list | grep konlpy
konlpy                             0.5.2
```

## MeCab 설치

```ruby
$ wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
$ tar -zxvf mecab-0.996-ko-0.9.2.tar.gz
$ cd mecab-0.996-ko-0.9.2/
$ ./configure
$ make
$ make check
$ sudo make install

-- MeCab 버전 확인 (오류 발생)
$ mecab --version
mecab: error while loading shared libraries: libmecab.so.2: cannot open shared object file: No such file or directory

-- 라이브러리 로딩 후 재 확인
$ sudo ldconfig
$ mecab --version
mecab of 0.996/ko-0.9.2
```

## Mecab-ko-dic 설치

```ruby
$ wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
$ tar -zxvf mecab-ko-dic-2.1.1-20180720.tar.gz
$ cd mecab-ko-dic-2.1.1-20180720/
$ sudo apt-get install automake
$ ./autogen.sh
$ ./configure
$ make
$ sudo make install
```

## Mecab python 설치

```ruby
$ git clone https://bitbucket.org/eunjeon/mecab-python-0.996.git
$ cd mecab-python-0.996/
$ python3 setup.py build
$ python3 setup.py install

-- Mecab 설치 확인
$ python
>>> from konlpy.tag import Mecab
>>> m = Mecab()
>>> m.pos('이상하게 생각해도 어쩔 수 없어 반했으니까')
[('이상', 'NNG'), ('하', 'XSV'), ('게', 'EC'), ('생각', 'NNG'), ('해도', 'XSV+EC'), ('어쩔', 'VV+ETM'), ('수', 'NNB'), ('없', 'VA'), ('어', 'EC'), ('반했', 'VV+EP'), ('으니까', 'EC')]
>>> m.pos('사탕처럼 달콤하다는데')
[('사탕', 'NNG'), ('처럼', 'JKB'), ('달콤', 'XR'), ('하', 'XSA'), ('다는데', 'EC')]
```

## RASA 1.8.3 에 한글 환경 셋팅

*   rasa/nlu/registry.py 파일에 다음을 추가한다 from rasa.nlu.extractors.crf\_entity\_extractor\_korean import CRFEntityExtractorKorean from rasa.nlu.tokenizers.korean\_tokenizer import KoreanTokenizer

# tokenizers

*   KoreanTokenizer,

# extractors

*   CRFEntityExtractorKorean,
*   (참고) anaconda3에 설치된 RASA 위치는 다음과 같다
    *   (MAC) /Users/maruhan/opt/anaconda3/envs/py369/lib/python3.6/site-packages/rasa
    *   (Linux) 확인
*   rasa/nlu/tokenizers 폴더에 첨부된 korean\_tokenizer.py 파일을 복사 한다.
*   rasa/nlu/extractors 폴더에 첨부된 crf\_entity\_extractor\_korean.py 파일을 복사 한다.

## rasa train 실행시 오류 수정

```ruby
File "/Users/maruhan/opt/anaconda3/envs/py369/lib/python3.6/site-packages/rasa/nlu/extractors/crf_entity_extractor_korean.py", line 7, in <module>

1. 업로드한 crf_entity_extractor_korean.py 파일 수정
from rasa.nlu.extractors import EntityExtractor ==> from rasa.nlu.extractors.extractor import EntityExtractor
from rasa.nlu.tokenizers import Token ==> from rasa.nlu.tokenizers.tokenizer import Token

2. 업로드한  korean_tokenizer.py.py 파일 수정
from rasa.nlu.tokenizers import Token, Tokenize ==> from rasa.nlu.tokenizers.tokenizer import Token, Tokenize
```

pipeline:

*   name: KoreanTokenizer
*   name: RegexFeaturizer
*   name: CRFEntityExtractorKorean
*   name: EntitySynonymMapper
*   name: CountVectorsFeaturizer &quot;token\_pattern&quot;: &#39;(?u)\\b\\w+\\b&#39; # 1개의 character도 인식하도록 regex 변경
*   name: EmbeddingIntentClassifier intent\_tokenization\_flag: true intent\_split\_symbol: &quot;+&quot;


# 첨부 파일

<figure class="file"><a href= "/attachments/crf_entity_extractor_korean.py" alt="crf_entity_extractor_korean">crf_entity_extractor_korean.py</a></figure>

<figure class="file"><a href= "/attachments/registry.py" alt="crf_entity_extractor_korean">registry.py</a></figure>

<figure class="file"><a href= "/attachments/korean_tokenizer.py" alt="crf_entity_extractor_korean">korean_tokenizer.py</a></figure>


End